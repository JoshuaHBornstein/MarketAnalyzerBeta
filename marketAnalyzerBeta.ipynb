{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Playground for testing market analysis and brokerage API connections. see market analyzer 2.0 for cleaner implementation"
      ],
      "metadata": {
        "id": "0Hods3tUpiCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#no need to run cell, was used for a 1-time scrape to get the 50 largerst publicly traded restaurants by market cap and now tickers are hardcoded.\n",
        "#Can be run again to update list if things change\n",
        "\"\"\"import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "TARGET_URL = f\"https://companiesmarketcap.com/restaurant-chains/largest-restaurant-chain-companies-by-market-cap/\"\n",
        "\n",
        "# make an HTTP request\n",
        "page = requests.get(TARGET_URL)\n",
        "\n",
        "\n",
        "# use an HTML parser to grab the content from \"page\"\n",
        "soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "\n",
        "# get the items that describe the stock\n",
        "items = soup.find_all(\"div\", {\"class\": \"company-code\"})\n",
        "ticker_symbols = [code.text.strip() for code in items]\"\"\"\n",
        "ticker_symbols = ['MCD', 'CMG', 'YUM', 'QSR', 'DRI', 'YUMC', 'DPZ', 'WING', '6862.HK', 'TXRH', 'AMR.AE', 'CAVA', '2702.T', 'JBFCF', 'SHAK', 'WEN', 'DMP.AX', 'PLAY', 'ARCO', 'BLMN', 'PZZA', 'DEVYANI.NS', 'SSPG.L', 'EAT', 'CAKE', 'SG', 'FWRG', 'JACK', 'EAT.MC', 'KRUS', 'MTY.TO', 'BJRI', 'PTLO', '9658.HK', 'DIN', '0341.HK', 'RTN.L', 'CHUY', 'BH', 'TAST', 'DENN', 'PBPB', '2753.TW', 'PZA.TO', 'LOCO', 'NATH', 'BARBEQUE.NS', 'GENK', 'RBD.NZ', 'THCH', 'FAT', '0052.HK', 'STKS', 'RRGB', 'NDLS', 'RAVE']"
      ],
      "metadata": {
        "id": "GlJOMy_JaThb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install oandapyV20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3BasYDu3HWd",
        "outputId": "6ef424da-9019-4d05-df95-2babd4353f2d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting oandapyV20\n",
            "  Downloading oandapyV20-0.7.2.tar.gz (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.6/51.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: oandapyV20\n",
            "  Building wheel for oandapyV20 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oandapyV20: filename=oandapyV20-0.7.2-py3-none-any.whl size=69779 sha256=2d2871be640077e7af4224a4894867f5e4946ab9a66ecf22d7e4858a925e1737\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/69/ab/a6da84a85b9bf3b5a98ca15c6c52b7854f32b10c70fe0531a1\n",
            "Successfully built oandapyV20\n",
            "Installing collected packages: oandapyV20\n",
            "Successfully installed oandapyV20-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import oandapyV20\n",
        "import oandapyV20.endpoints.accounts as accounts\n",
        "import oandapyV20.endpoints.orders as orders\n",
        "from oandapyV20.contrib.requests import MarketOrderRequest\n",
        "import json\n",
        "\n",
        "# Initialize the API client\n",
        "# Access token is for a demo trading account, DO NOT hardcode tokens for real money accounts, use a secure configuration method\n",
        "client = oandapyV20.API(access_token='8e00ca0c834c14f4855707d113b8625e-66f48575bc06e2a7621f83dae68c7607')\n",
        "\n",
        "# Fetch account details\n",
        "# Demo account_id\n",
        "account_id = '101-001-28514425-001'\n",
        "r = accounts.AccountDetails(account_id)\n",
        "account_details = client.request(r)\n",
        "print(account_details)\n",
        "\n",
        "# Test connection: Place a market order to buy 1 Euro\n",
        "data = {\n",
        "    \"order\": {\n",
        "        \"type\": \"MARKET\",  # Specifies the type of order\n",
        "        \"instrument\": \"EUR_USD\",\n",
        "        \"units\": \"1\",  # Positive for buy, negative for sell\n",
        "        \"timeInForce\": \"FOK\",  # Fills or kills the order\n",
        "        \"positionFill\": \"DEFAULT\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create and send the order request\n",
        "order = orders.OrderCreate(accountID=account_id, data=data)\n",
        "response = client.request(order)\n",
        "\n",
        "print(json.dumps(response, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92NMxjAK3M7e",
        "outputId": "57dc5660-5d4f-4750-b909-562cc4899d7f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'account': {'guaranteedStopLossOrderMode': 'DISABLED', 'hedgingEnabled': False, 'id': '101-001-28514425-001', 'createdTime': '2024-03-03T18:28:56.625100678Z', 'currency': 'USD', 'createdByUserID': 28514425, 'alias': 'Primary', 'marginRate': '0.02', 'lastTransactionID': '12', 'balance': '99999.9854', 'openTradeCount': 3, 'openPositionCount': 1, 'pendingOrderCount': 0, 'pl': '0.0000', 'resettablePL': '0.0000', 'resettablePLTime': '0', 'financing': '-0.0146', 'commission': '0.0000', 'dividendAdjustment': '0', 'guaranteedExecutionFees': '0.0000', 'orders': [], 'positions': [{'instrument': 'EUR_USD', 'long': {'units': '300', 'averagePrice': '1.08569', 'pl': '0.0000', 'resettablePL': '0.0000', 'financing': '-0.0146', 'dividendAdjustment': '0.0000', 'guaranteedExecutionFees': '0.0000', 'tradeIDs': ['7', '9', '12'], 'unrealizedPL': '-0.3260'}, 'short': {'units': '0', 'pl': '0.0000', 'resettablePL': '0.0000', 'financing': '0.0000', 'dividendAdjustment': '0.0000', 'guaranteedExecutionFees': '0.0000', 'unrealizedPL': '0.0000'}, 'pl': '0.0000', 'resettablePL': '0.0000', 'financing': '-0.0146', 'commission': '0.0000', 'dividendAdjustment': '0.0000', 'guaranteedExecutionFees': '0.0000', 'unrealizedPL': '-0.3260', 'marginUsed': '6.5081'}], 'trades': [{'id': '7', 'instrument': 'EUR_USD', 'price': '1.08570', 'openTime': '2024-03-04T21:36:02.438243486Z', 'initialUnits': '100', 'initialMarginRequired': '2.1713', 'state': 'OPEN', 'currentUnits': '100', 'realizedPL': '0.0000', 'financing': '-0.0073', 'dividendAdjustment': '0.0000', 'unrealizedPL': '-0.1100', 'marginUsed': '2.1694'}, {'id': '9', 'instrument': 'EUR_USD', 'price': '1.08567', 'openTime': '2024-03-04T21:38:22.920493693Z', 'initialUnits': '100', 'initialMarginRequired': '2.1712', 'state': 'OPEN', 'currentUnits': '100', 'realizedPL': '0.0000', 'financing': '-0.0073', 'dividendAdjustment': '0.0000', 'unrealizedPL': '-0.1070', 'marginUsed': '2.1694'}, {'id': '12', 'instrument': 'EUR_USD', 'price': '1.08569', 'openTime': '2024-03-04T22:06:45.813074195Z', 'initialUnits': '100', 'initialMarginRequired': '2.1712', 'state': 'OPEN', 'currentUnits': '100', 'realizedPL': '0.0000', 'financing': '0.0000', 'dividendAdjustment': '0.0000', 'unrealizedPL': '-0.1090', 'marginUsed': '2.1694'}], 'unrealizedPL': '-0.3260', 'NAV': '99999.6594', 'marginUsed': '6.5081', 'marginAvailable': '99993.1513', 'positionValue': '325.4040', 'marginCloseoutUnrealizedPL': '-0.3030', 'marginCloseoutNAV': '99999.6824', 'marginCloseoutMarginUsed': '6.5081', 'marginCloseoutPositionValue': '325.4040', 'marginCloseoutPercent': '0.00003', 'withdrawalLimit': '99993.1513', 'marginCallMarginUsed': '6.5081', 'marginCallPercent': '0.00007'}, 'lastTransactionID': '12'}\n",
            "{\n",
            "  \"orderCreateTransaction\": {\n",
            "    \"id\": \"13\",\n",
            "    \"accountID\": \"101-001-28514425-001\",\n",
            "    \"userID\": 28514425,\n",
            "    \"batchID\": \"13\",\n",
            "    \"requestID\": \"97242755787900435\",\n",
            "    \"time\": \"2024-03-05T12:53:02.243682285Z\",\n",
            "    \"type\": \"MARKET_ORDER\",\n",
            "    \"instrument\": \"EUR_USD\",\n",
            "    \"units\": \"100\",\n",
            "    \"timeInForce\": \"FOK\",\n",
            "    \"positionFill\": \"DEFAULT\",\n",
            "    \"reason\": \"CLIENT_ORDER\"\n",
            "  },\n",
            "  \"orderFillTransaction\": {\n",
            "    \"id\": \"14\",\n",
            "    \"accountID\": \"101-001-28514425-001\",\n",
            "    \"userID\": 28514425,\n",
            "    \"batchID\": \"13\",\n",
            "    \"requestID\": \"97242755787900435\",\n",
            "    \"time\": \"2024-03-05T12:53:02.243682285Z\",\n",
            "    \"type\": \"ORDER_FILL\",\n",
            "    \"orderID\": \"13\",\n",
            "    \"instrument\": \"EUR_USD\",\n",
            "    \"units\": \"100\",\n",
            "    \"requestedUnits\": \"100\",\n",
            "    \"price\": \"1.08475\",\n",
            "    \"pl\": \"0.0000\",\n",
            "    \"quotePL\": \"0\",\n",
            "    \"financing\": \"0.0000\",\n",
            "    \"baseFinancing\": \"0\",\n",
            "    \"commission\": \"0.0000\",\n",
            "    \"accountBalance\": \"99999.9854\",\n",
            "    \"gainQuoteHomeConversionFactor\": \"1\",\n",
            "    \"lossQuoteHomeConversionFactor\": \"1\",\n",
            "    \"guaranteedExecutionFee\": \"0.0000\",\n",
            "    \"quoteGuaranteedExecutionFee\": \"0\",\n",
            "    \"halfSpreadCost\": \"0.0075\",\n",
            "    \"fullVWAP\": \"1.08475\",\n",
            "    \"reason\": \"MARKET_ORDER\",\n",
            "    \"tradeOpened\": {\n",
            "      \"price\": \"1.08475\",\n",
            "      \"tradeID\": \"14\",\n",
            "      \"units\": \"100\",\n",
            "      \"guaranteedExecutionFee\": \"0.0000\",\n",
            "      \"quoteGuaranteedExecutionFee\": \"0\",\n",
            "      \"halfSpreadCost\": \"0.0075\",\n",
            "      \"initialMarginRequired\": \"2.1694\"\n",
            "    },\n",
            "    \"fullPrice\": {\n",
            "      \"closeoutBid\": \"1.08460\",\n",
            "      \"closeoutAsk\": \"1.08475\",\n",
            "      \"timestamp\": \"2024-03-05T12:52:52.762556020Z\",\n",
            "      \"bids\": [\n",
            "        {\n",
            "          \"price\": \"1.08460\",\n",
            "          \"liquidity\": \"10000000\"\n",
            "        }\n",
            "      ],\n",
            "      \"asks\": [\n",
            "        {\n",
            "          \"price\": \"1.08475\",\n",
            "          \"liquidity\": \"10000000\"\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    \"homeConversionFactors\": {\n",
            "      \"gainQuoteHome\": {\n",
            "        \"factor\": \"1\"\n",
            "      },\n",
            "      \"lossQuoteHome\": {\n",
            "        \"factor\": \"1\"\n",
            "      },\n",
            "      \"gainBaseHome\": {\n",
            "        \"factor\": \"1.07925660\"\n",
            "      },\n",
            "      \"lossBaseHome\": {\n",
            "        \"factor\": \"1.09010340\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"relatedTransactionIDs\": [\n",
            "    \"13\",\n",
            "    \"14\"\n",
            "  ],\n",
            "  \"lastTransactionID\": \"14\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sns.set_style('whitegrid')\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "%matplotlib inline\n",
        "\n",
        "# For reading stock data from yahoo\n",
        "from pandas_datareader.data import DataReader\n",
        "import yfinance as yf\n",
        "from pandas_datareader import data as pdr\n",
        "\n",
        "yf.pdr_override()\n",
        "\n",
        "# For time stamps\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "end = datetime.now()\n",
        "start = datetime(end.year - 1, end.month, end.day)\n"
      ],
      "metadata": {
        "id": "WPP_3zu-BrOv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create list of restaurant ticker symbols called ticker symbols\n",
        "ticker_list = ['MCD', 'CMG', 'YUM', 'QSR', 'DRI', 'YUMC', 'DPZ', 'WING', '6862.HK', 'TXRH', 'CAVA', '2702.T', 'JBFCF', 'SHAK', 'WEN', 'DMP.AX', 'PLAY', 'ARCO', 'BLMN', 'PZZA', 'DEVYANI.NS', 'SSPG.L', 'EAT', 'CAKE', 'SG', 'FWRG', 'JACK', 'EAT.MC', 'KRUS', 'MTY.TO', 'BJRI', 'PTLO', '9658.HK', 'DIN', '0341.HK', 'CHUY', 'BH', 'TAST', 'DENN', 'PBPB', '2753.TW', 'PZA.TO', 'LOCO', 'NATH', 'BARBEQUE.NS', 'GENK', 'RBD.NZ', 'THCH', 'FAT', '0052.HK', 'STKS', 'RRGB', 'NDLS', 'RAVE']\n",
        "#removed 'AMR.AE' and 'RTN.L'\n",
        "all_data = pd.DataFrame()\n",
        "# Define a function to calculate RSI\n",
        "def calculate_rsi(data, window=14):\n",
        "    delta = data.diff(1)\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
        "\n",
        "    rs = gain / loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "# Define a function to calculate SMA\n",
        "def calculate_sma(data, window=20):\n",
        "    return data.rolling(window=window).mean()\n",
        "\n",
        "for ticker in ticker_list:\n",
        "    # Fetch the daily data\n",
        "    daily_data = yf.download(ticker, start=start, end=end)[['Close', 'Volume']].copy()\n",
        "    daily_data.reset_index(inplace=True)\n",
        "\n",
        "    daily_data['RSI'] = calculate_rsi(daily_data['Close'])\n",
        "    daily_data['SMA_20'] = calculate_sma(daily_data['Close'])\n",
        "\n",
        "    # Add lagged features for 'Close' and 'Volume'\n",
        "    daily_data['Close_lag1'] = daily_data['Close'].shift(1)\n",
        "    daily_data['Volume_lag1'] = daily_data['Volume'].shift(1)\n",
        "\n",
        "    # Fetch the market cap and target price (mean)\n",
        "    ticker_obj = yf.Ticker(ticker)\n",
        "    info = ticker_obj.info\n",
        "    market_cap = info.get('marketCap', None)\n",
        "    target_mean_price = info.get('targetMeanPrice', None)\n",
        "\n",
        "    # Add the ticker, market cap, and target mean price to the daily data\n",
        "    daily_data['Ticker'] = ticker\n",
        "    daily_data['Market_Cap'] = market_cap\n",
        "    daily_data['Target_Mean_Price'] = target_mean_price\n",
        "\n",
        "    # Append to the main DataFrame\n",
        "    all_data = pd.concat([all_data, daily_data])\n",
        "\n",
        "# Convert 'Ticker' column to one-hot encoded columns\n",
        "#all_data = pd.get_dummies(all_data, columns=['Ticker'])\n",
        "\n",
        "print(all_data.shape)\n",
        "print(all_data.head())"
      ],
      "metadata": {
        "id": "ZI12xwORZNDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8cb299-ff3c-45ee-a139-a0162973083d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13363, 10)\n",
            "        Date       Close   Volume  RSI  SMA_20  Close_lag1  Volume_lag1  \\\n",
            "0 2023-03-06  270.640015  2217600  NaN     NaN         NaN          NaN   \n",
            "1 2023-03-07  267.130005  2766600  NaN     NaN  270.640015    2217600.0   \n",
            "2 2023-03-08  265.329987  2314000  NaN     NaN  267.130005    2766600.0   \n",
            "3 2023-03-09  261.630005  2339300  NaN     NaN  265.329987    2314000.0   \n",
            "4 2023-03-10  262.029999  3093100  NaN     NaN  261.630005    2339300.0   \n",
            "\n",
            "  Ticker    Market_Cap  Target_Mean_Price  \n",
            "0    MCD  210073796608             327.05  \n",
            "1    MCD  210073796608             327.05  \n",
            "2    MCD  210073796608             327.05  \n",
            "3    MCD  210073796608             327.05  \n",
            "4    MCD  210073796608             327.05  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ukV3_SM9T5u",
        "outputId": "1ba67de3-6b2b-41b9-831b-130be3312ac6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Date', 'Close', 'Volume', 'RSI', 'SMA_20', 'Close_lag1', 'Volume_lag1',\n",
            "       'Ticker', 'Market_Cap', 'Target_Mean_Price'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Feature Preparation\n",
        "# Drop rows with missing values to simplify the example\n",
        "all_data.dropna(inplace=True)\n",
        "\n",
        "# Step 2: Label Creation\n",
        "# Shift the 'Close' price to create the target variable: 1 if the price goes up, else 0\n",
        "all_data['Target'] = (all_data.groupby('Ticker')['Close'].shift(-1) > all_data['Close']).astype(int)\n",
        "\n",
        "# Filter out the last row for each ticker since it won't have a label\n",
        "all_data = all_data.groupby('Ticker').apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
        "\n",
        "all_data = pd.get_dummies(all_data, columns=['Ticker'])\n",
        "\n",
        "# Assuming we are focusing on one stock for simplicity, filter by ticker if desired\n",
        "# all_data = all_data[all_data['Ticker'] == 'AAPL']\n",
        "\n",
        "# Separate features and target variable\n",
        "X = all_data[['RSI', 'SMA_20', 'Close_lag1', 'Volume_lag1']]\n",
        "y = all_data['Target']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 3: Model Training\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldzHNCCp9G90",
        "outputId": "7c62d21a-b9ad-4141-a862-08ae564e6776"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5122067975107707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# URL of the Wikipedia page containing the list of S&P 500 companies\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "\n",
        "# Use pandas to read the table from the webpage\n",
        "sp500_table = pd.read_html(url, attrs={\"id\": \"constituents\"})[0]\n",
        "\n",
        "# The DataFrame 'sp500_table' now contains the list of S&P 500 companies\n",
        "sp500_symbols = sp500_table['Symbol'].tolist()\n",
        "\n",
        "# Optionally, extract other information such as the industry sector\n",
        "sp500_sectors = sp500_table[['Symbol', 'GICS Sector']].set_index('Symbol').to_dict()['GICS Sector']\n",
        "\n",
        "#print(sp500_symbols)  # Print the first 10 ticker symbols to verify\n",
        "print(list(sp500_sectors.items())[:10])  # Print the sector information for the first 10 companies\n",
        "sp500_symbols_hardcoded = ['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A', 'APD', 'ABNB', 'AKAM', 'ALB', 'ARE', 'ALGN', 'ALLE', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AMCR', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'AME', 'AMGN', 'APH', 'ADI', 'ANSS', 'AON', 'APA', 'AAPL', 'AMAT', 'APTV', 'ACGL', 'ADM', 'ANET', 'AJG', 'AIZ', 'T', 'ATO', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'AXON', 'BKR', 'BALL', 'BAC', 'BK', 'BBWI', 'BAX', 'BDX', 'BRK-B', 'BBY', 'BIO', 'TECH', 'BIIB', 'BLK', 'BX', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BMY', 'AVGO', 'BR', 'BRO', 'BF-B', 'BLDR', 'BG', 'CDNS', 'CZR', 'CPT', 'CPB', 'COF', 'CAH', 'KMX', 'CCL', 'CARR', 'CTLT', 'CAT', 'CBOE', 'CBRE', 'CDW', 'CE', 'COR', 'CNC', 'CNP', 'CF', 'CHRW', 'CRL', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'COP', 'ED', 'STZ', 'CEG', 'COO', 'CPRT', 'GLW', 'CTVA', 'CSGP', 'COST', 'CTRA', 'CCI', 'CSX', 'CMI', 'CVS', 'DHR', 'DRI', 'DVA', 'DAY', 'DE', 'DAL', 'XRAY', 'DVN', 'DXCM', 'FANG', 'DLR', 'DFS', 'DG', 'DLTR', 'D', 'DPZ', 'DOV', 'DOW', 'DHI', 'DTE', 'DUK', 'DD', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'ELV', 'LLY', 'EMR', 'ENPH', 'ETR', 'EOG', 'EPAM', 'EQT', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'ETSY', 'EG', 'EVRG', 'ES', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FDS', 'FICO', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FSLR', 'FE', 'FI', 'FLT', 'FMC', 'F', 'FTNT', 'FTV', 'FOXA', 'FOX', 'BEN', 'FCX', 'GRMN', 'IT', 'GEHC', 'GEN', 'GNRC', 'GD', 'GE', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GL', 'GS', 'HAL', 'HIG', 'HAS', 'HCA', 'PEAK', 'HSIC', 'HSY', 'HES', 'HPE', 'HLT', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HWM', 'HPQ', 'HUBB', 'HUM', 'HBAN', 'HII', 'IBM', 'IEX', 'IDXX', 'ITW', 'ILMN', 'INCY', 'IR', 'PODD', 'INTC', 'ICE', 'IFF', 'IP', 'IPG', 'INTU', 'ISRG', 'IVZ', 'INVH', 'IQV', 'IRM', 'JBHT', 'JBL', 'JKHY', 'J', 'JNJ', 'JCI', 'JPM', 'JNPR', 'K', 'KVUE', 'KDP', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KLAC', 'KHC', 'KR', 'LHX', 'LH', 'LRCX', 'LW', 'LVS', 'LDOS', 'LEN', 'LIN', 'LYV', 'LKQ', 'LMT', 'L', 'LOW', 'LULU', 'LYB', 'MTB', 'MRO', 'MPC', 'MKTX', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MTCH', 'MKC', 'MCD', 'MCK', 'MDT', 'MRK', 'META', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MRNA', 'MHK', 'MOH', 'TAP', 'MDLZ', 'MPWR', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'NDAQ', 'NTAP', 'NFLX', 'NEM', 'NWSA', 'NWS', 'NEE', 'NKE', 'NI', 'NDSN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'NVR', 'NXPI', 'ORLY', 'OXY', 'ODFL', 'OMC', 'ON', 'OKE', 'ORCL', 'OTIS', 'PCAR', 'PKG', 'PANW', 'PARA', 'PH', 'PAYX', 'PAYC', 'PYPL', 'PNR', 'PEP', 'PFE', 'PCG', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'POOL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PTC', 'PSA', 'PHM', 'QRVO', 'PWR', 'QCOM', 'DGX', 'RL', 'RJF', 'RTX', 'O', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RVTY', 'RHI', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'SPGI', 'CRM', 'SBAC', 'SLB', 'STX', 'SRE', 'NOW', 'SHW', 'SPG', 'SWKS', 'SJM', 'SNA', 'SO', 'LUV', 'SWK', 'SBUX', 'STT', 'STLD', 'STE', 'SYK', 'SYF', 'SNPS', 'SYY', 'TMUS', 'TROW', 'TTWO', 'TPR', 'TRGP', 'TGT', 'TEL', 'TDY', 'TFX', 'TER', 'TSLA', 'TXN', 'TXT', 'TMO', 'TJX', 'TSCO', 'TT', 'TDG', 'TRV', 'TRMB', 'TFC', 'TYL', 'TSN', 'USB', 'UBER', 'UDR', 'ULTA', 'UNP', 'UAL', 'UPS', 'URI', 'UNH', 'UHS', 'VLO', 'VTR', 'VLTO', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VFC', 'VTRS', 'VICI', 'V', 'VMC', 'WRB', 'WAB', 'WBA', 'WMT', 'DIS', 'WBD', 'WM', 'WAT', 'WEC', 'WFC', 'WELL', 'WST', 'WDC', 'WRK', 'WY', 'WHR', 'WMB', 'WTW', 'GWW', 'WYNN', 'XEL', 'XYL', 'YUM', 'ZBRA', 'ZBH', 'ZION', 'ZTS']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJjGDMB-aNYl",
        "outputId": "ee35fd81-5776-41a8-fd78-f0b337b93cc7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('MMM', 'Industrials'), ('AOS', 'Industrials'), ('ABT', 'Health Care'), ('ABBV', 'Health Care'), ('ACN', 'Information Technology'), ('ADBE', 'Information Technology'), ('AMD', 'Information Technology'), ('AES', 'Utilities'), ('AFL', 'Financials'), ('A', 'Health Care')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['Symbol', 'Date', 'Close', 'Volume', 'Market Cap', 'Industry']\n",
        "data_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "rows_list = []\n",
        "counter = 0\n",
        "# Fetch historical data for each symbol and append it to the DataFrame\n",
        "for symbol in sp500_symbols_hardcoded:\n",
        "    counter+=1\n",
        "    if (counter % 100 == 0):\n",
        "      print(\"iteration number\" + str(counter))\n",
        "    stock = yf.Ticker(symbol)\n",
        "    hist = stock.history(period=\"10y\")\n",
        "      # Fetch 10 years of historical data\n",
        "\n",
        "    info = stock.info\n",
        "    market_cap = info.get('marketCap', 'Unknown')\n",
        "    industry = info.get('industry', 'Unknown')\n",
        "\n",
        "    # Append each row of historical data to the DataFrame\n",
        "    for date, row in hist.iterrows():\n",
        "        rows_list.append({\n",
        "            'Symbol': symbol,\n",
        "            'Date': date,\n",
        "            'Close': row['Close'],\n",
        "            'Volume': row['Volume'],\n",
        "            'Market Cap': market_cap,\n",
        "            'Industry': industry\n",
        "        })\n",
        "\n",
        "data_df = pd.concat([data_df, pd.DataFrame(rows_list)], ignore_index=True)\n",
        "print(data_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kHUS-CUDPV8",
        "outputId": "1cb52021-13a4-4339-a591-bc521f68cd1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration number100\n",
            "iteration number200\n",
            "iteration number300\n",
            "iteration number400\n",
            "iteration number500\n",
            "(1236644, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_sma(data, window=20):\n",
        "    \"\"\"Calculates Simple Moving Average\"\"\"\n",
        "    return data.rolling(window=window).mean()\n",
        "\n",
        "def calculate_rsi(data, window=14):\n",
        "    \"\"\"Calculates Relative Strength Index\"\"\"\n",
        "    delta = data.diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
        "\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))"
      ],
      "metadata": {
        "id": "CNW7ZSlyeAHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Symbol' and apply the technical indicator functions\n",
        "data_df['SMA_20'] = data_df.groupby('Symbol')['Close'].apply(lambda x: calculate_sma(x, 20))\n",
        "data_df['RSI_14'] = data_df.groupby('Symbol')['Close'].apply(lambda x: calculate_rsi(x, 14))\n",
        "\n",
        "# Normalize features (example using MinMaxScaler for 'Close' and 'Volume')\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Note: Typically, you should fit the scaler on the training dataset only, then transform both training and test datasets.\n",
        "# Here, for simplicity, we're applying it directly.\n",
        "data_df[['Close', 'Volume']] = scaler.fit_transform(data_df[['Close', 'Volume']])\n",
        "\n",
        "# Create lagged features for 'Close' and 'Volume'\n",
        "def create_lagged_features(df, n_lags=5, columns=['Close', 'Volume']):\n",
        "    for col in columns:\n",
        "        for lag in range(1, n_lags + 1):\n",
        "            df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
        "    return df\n",
        "\n",
        "# Apply lagged feature creation to each symbol\n",
        "data_df = data_df.groupby('Symbol').apply(lambda x: create_lagged_features(x, n_lags=5))\n",
        "\n",
        "# Drop rows with NaN values that were introduced by lagging\n",
        "data_df.dropna(inplace=True)\n",
        "\n",
        "# Your data_df now has SMA, RSI, normalized 'Close' and 'Volume', and their lagged features\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2KtRGkUeEno",
        "outputId": "31aaf750-6176-4cb4-f47c-ab4039f427c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-1fd2a1268a99>:2: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  data_df['SMA_20'] = data_df.groupby('Symbol')['Close'].apply(lambda x: calculate_sma(x, 20))\n",
            "<ipython-input-13-1fd2a1268a99>:3: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  data_df['RSI_14'] = data_df.groupby('Symbol')['Close'].apply(lambda x: calculate_rsi(x, 14))\n",
            "<ipython-input-13-1fd2a1268a99>:21: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  data_df = data_df.groupby('Symbol').apply(lambda x: create_lagged_features(x, n_lags=5))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'data_df' already has SMA, RSI, normalized 'Close' and 'Volume', and their lagged features\n",
        "\n",
        "# Apply one-hot encoding to the 'Symbol' column to handle it as a categorical variable\n",
        "data_df = pd.get_dummies(data_df, columns=['Symbol'])\n",
        "\n",
        "# At this point, 'data_df' includes:\n",
        "# - Normalized 'Close' and 'Volume'\n",
        "# - SMA and RSI technical indicators\n",
        "# - Lagged features for 'Close' and 'Volume'\n",
        "# - One-hot encoded stock symbols\n",
        "\n",
        "# Optionally, you can also normalize the SMA and RSI features if they haven't been normalized yet\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Assuming SMA and RSI might not be scaled, you can scale them here\n",
        "data_df[['SMA_20', 'RSI_14']] = scaler.fit_transform(data_df[['SMA_20', 'RSI_14']])\n"
      ],
      "metadata": {
        "id": "EelTUlGMenJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_df.shape)\n",
        "print(data_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKE7-11af_8Z",
        "outputId": "10f14049-0504-4d5f-9b20-a68c16b6768f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1226787, 520)\n",
            "Index(['Date', 'Close', 'Volume', 'Market Cap', 'Industry', 'SMA_20', 'RSI_14',\n",
            "       'Close_lag_1', 'Close_lag_2', 'Close_lag_3',\n",
            "       ...\n",
            "       'Symbol_WYNN', 'Symbol_XEL', 'Symbol_XOM', 'Symbol_XRAY', 'Symbol_XYL',\n",
            "       'Symbol_YUM', 'Symbol_ZBH', 'Symbol_ZBRA', 'Symbol_ZION', 'Symbol_ZTS'],\n",
            "      dtype='object', length=520)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"def create_sequences(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X.iloc[i:(i + time_steps)].values)\n",
        "        ys.append(y.iloc[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "# Assuming you want to predict the next day's 'Close' price\n",
        "# Let's separate the features (X) and the target (y)\n",
        "X = data_df.drop(['Close'], axis=1)  # Features include all but the target 'Close'\n",
        "y = data_df['Close']  # Target variable\n",
        "\n",
        "# Number of time steps you want to look back\n",
        "time_steps = 5\n",
        "\n",
        "# Create sequences\n",
        "X_seq, y_seq = create_sequences(X, y, time_steps=time_steps)\n",
        "\n",
        "# Now, X_seq and y_seq are ready for LSTM model input\"\"\"\n",
        "#issue with way to much data, perhaps choose less time, less features, and/or, less stocks\n"
      ],
      "metadata": {
        "id": "ulISqd8ee07k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(yf.Ticker)"
      ],
      "metadata": {
        "id": "g_s8JoB7Ofcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(yf.data)"
      ],
      "metadata": {
        "id": "IE3HsrWIOuo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "luckinCoffee = yf.download(\"lkncy\", start, end)\n",
        "lkncy = yf.Ticker(\"lkncy\")\n",
        "aapl = yf.Ticker(\"aapl\")\n",
        "apple1m = aapl.history(interval = \"1m\", start = '2024-02-25', end = '2024-03-01')\n",
        "print(lkncy.info)\n",
        "print(apple1m.head())\n",
        "print(aapl.major_holders)\n",
        "print(aapl.recommendations)\n",
        "#print(lkncy.major_holders)\n",
        "luckinCoffee.tail(10)\n",
        "##print(luckinCoffee)"
      ],
      "metadata": {
        "id": "28lBJtL6IVFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example: Predicting Luckin's stock price (dummy data and process)\n",
        "\n",
        "data = luckinCoffee\n",
        "\n",
        "# Preprocess data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1,1))\n",
        "\n",
        "# Create a dataset for training\n",
        "def create_dataset(data, time_step=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data)-time_step-1):\n",
        "        a = data[i:(i+time_step), 0]\n",
        "        X.append(a)\n",
        "        Y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "time_step = 100\n",
        "X, y = create_dataset(scaled_data, time_step)\n",
        "X = X.reshape(X.shape[0],X.shape[1],1)\n",
        "\n",
        "# Split data into train and test\n",
        "train_size = int(len(X)*0.67)\n",
        "test_size = len(X) - train_size\n",
        "X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
        "y_train, y_test = y[0:train_size], y[train_size:len(y)]\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(100, 1)))\n",
        "model.add(LSTM(50, return_sequences=False))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, batch_size=1, epochs=1)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Evaluate your model (e.g., using RMSE)\n"
      ],
      "metadata": {
        "id": "yhyB7-HHBTkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print predictions\n",
        "print(X_test)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "EmSZoywBIHBM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}